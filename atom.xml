<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://huran111.github.io</id>
    <title>胡的博客</title>
    <updated>2019-09-30T01:13:20.999Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://huran111.github.io"/>
    <link rel="self" href="https://huran111.github.io/atom.xml"/>
    <subtitle>知其然，知其所以然</subtitle>
    <logo>https://huran111.github.io/images/avatar.png</logo>
    <icon>https://huran111.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, 胡的博客</rights>
    <entry>
        <title type="html"><![CDATA[kafka入门介绍]]></title>
        <id>https://huran111.github.io/post/kafka-ru-men-jie-shao</id>
        <link href="https://huran111.github.io/post/kafka-ru-men-jie-shao">
        </link>
        <updated>2019-09-29T08:39:01.000Z</updated>
        <content type="html"><![CDATA[<h3 id="kafka作为一个分布式的流平台这到底意味着什么">Kafka作为一个分布式的流平台，这到底意味着什么？</h3>
<p>我们认为，一个流处理平台具有三个关键能力：</p>
<p>发布和订阅消息(流)，在这方面，它类似于一个消息队列或企业消息系统。
以容错(故障转移)的方式存储消息(流)。
在消息流发生时处理它们。
什么是kafka的优势？它主要应用于2大类应用：
构建实时的流数据管道，可靠地获取系统和应用程序之间的数据。
构建实时流的应用程序，对数据流进行转换或反应。
要了解kafka是如何做这些事情的，让我们从下到上深入探讨kafka的能力。</p>
<p>首先几个概念：
kafka作为一个集群运行在一个或多个服务器上。
kafka集群存储的消息是以topic为类别记录的。
每个消息（也叫记录record，我习惯叫消息）是由一个key，一个value和时间戳构成。
kafka有四个核心API：
应用程序使用 Producer API 发布消息到1个或多个topic（主题）。
应用程序使用 Consumer API 来订阅一个或多个topic，并处理产生的消息。
应用程序使用 Streams API 充当一个流处理器，从1个或多个topic消费输入流，并生产一个输出流到1个或多个输出topic，有效地将输入流转换到输出流。
Connector API允许构建或运行可重复使用的生产者或消费者，将topic连接到现有的应用程序或数据系统。例如，一个关系数据库的连接器可捕获每一个变化。
<img src="https://huran111.github.io/post-images/1569746404947.png" alt=""></p>
<h3 id="首先来了解一下kafka所使用的基本术语">首先来了解一下Kafka所使用的基本术语：</h3>
<p>Topic
Kafka将消息种子(Feed)分门别类，每一类的消息称之为一个主题(Topic).</p>
<p>Producer
发布消息的对象称之为主题生产者(Kafka topic producer)</p>
<p>Consumer
订阅消息并处理发布的消息的种子的对象称之为主题消费者(consumers)</p>
<p>Broker
已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理(Broker). 消费者可以订阅一个或多个主题（topic），并从Broker拉数据，从而消费这些已发布的消息。</p>
<h3 id="主题和日志-topic和log">主题和日志 (Topic和Log)</h3>
<p><img src="https://huran111.github.io/post-images/1569746451359.png" alt=""></p>
<p>每一个分区都是一个顺序的、不可变的消息队列， 并且可以持续的添加。分区中的消息都被分了一个序列号，称之为偏移量(offset)，在每个分区中此偏移量都是唯一的。</p>
<p>Kafka集群保持所有的消息，直到它们过期， 无论消息是否被消费了。 实际上消费者所持有的仅有的元数据就是这个偏移量，也就是消费者在这个log中的位置。 这个偏移量由消费者控制：正常情况当消费者消费消息的时候，偏移量也线性的的增加。但是实际偏移量由消费者控制，消费者可以将偏移量重置为更老的一个偏移量，重新读取消息。 可以看到这种设计对消费者来说操作自如， 一个消费者的操作不会影响其它消费者对此log的处理。 再说说分区。Kafka中采用分区的设计有几个目的。一是可以处理更多的消息，不受单台服务器的限制。Topic拥有多个分区意味着它可以不受限的处理更多的数据。第二，分区可以作为并行处理的单元，稍后会谈到这一点。
<img src="https://huran111.github.io/post-images/1569746475414.png" alt=""></p>
<h3 id="kafka作为一个存储系统">kafka作为一个存储系统</h3>
<p>所有发布消息到消息队列和消费分离的系统，实际上都充当了一个存储系统（发布的消息先存储起来）。Kafka比别的系统的优势是它是一个非常高性能的存储系统。</p>
<p>写入到kafka的数据将写到磁盘并复制到集群中保证容错性。并允许生产者等待消息应答，直到消息完全写入。</p>
<p>kafka的磁盘结构 - 无论你服务器上有50KB或50TB，执行是相同的。</p>
<p>client来控制读取数据的位置。你还可以认为kafka是一种专用于高性能，低延迟，提交日志存储，复制，和传播特殊用途的分布式文件系统。</p>
<h3 id="kafka的流处理">kafka的流处理</h3>
<p>仅仅读，写和存储是不够的，kafka的目标是实时的流处理。</p>
<p>在kafka中，流处理持续获取输入topic的数据，进行处理加工，然后写入输出topic。例如，一个零售APP，接收销售和出货的输入流，统计数量或调整价格后输出。</p>
<p>可以直接使用producer和consumer API进行简单的处理。对于复杂的转换，Kafka提供了更强大的Streams API。可构建聚合计算或连接流到一起的复杂应用程序。</p>
<p>助于解决此类应用面临的硬性问题：处理无序的数据，代码更改的再处理，执行状态计算等。</p>
<p>Sterams API在Kafka中的核心：使用producer和consumer API作为输入，利用Kafka做状态存储，使用相同的组机制在stream处理器实例之间进行容错保障。</p>
<p>消息传递，存储和流处理的组合看似反常，但对于Kafka作为流式处理平台的作用至关重要。</p>
<p>像HDFS这样的分布式文件系统允许存储静态文件来进行批处理。这样系统可以有效地存储和处理来自过去的历史数据。</p>
<p>传统企业的消息系统允许在你订阅之后处理未来的消息：在未来数据到达时处理它。</p>
<p>Kafka结合了这两种能力，这种组合对于kafka作为流处理应用和流数据管道平台是至关重要的。</p>
<p>批处理以及消息驱动应用程序的流处理的概念：通过组合存储和低延迟订阅，流处理应用可以用相同的方式对待过去和未来的数据。它是一个单一的应用程序，它可以处理历史的存储数据，当它处理到最后一个消息时，它进入等待未来的数据到达，而不是结束。</p>
<p>同样，对于流数据管道（pipeline），订阅实时事件的组合使得可以将Kafka用于非常低延迟的管道；但是，可靠地存储数据的能力使得它可以将其用于必须保证传递的关键数据，或与仅定期加载数据或长时间维护的离线系统集成在一起。流处理可以在数据到达时转换它。
<img src="https://huran111.github.io/post-images/1569746708640.png" alt="">
<img src="https://huran111.github.io/post-images/1569746724920.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flume + Kafka + Spark Streaming整合]]></title>
        <id>https://huran111.github.io/post/flume-kafka-spark-streaming-zheng-he</id>
        <link href="https://huran111.github.io/post/flume-kafka-spark-streaming-zheng-he">
        </link>
        <updated>2019-09-29T04:39:40.000Z</updated>
        <content type="html"><![CDATA[<p><strong>1. 启动kafka,创建一个主题</strong>
./kafka-topics.sh –create –zookeeper hadoop:2181 –replication-factor 1 –partitions 1 –topic flume-kafka-streaming-topic</p>
<p><strong>2.删除主题：</strong>
/bin/kafka-topics –delete –topic test –zookeeper localhost:2181</p>
<p><strong>3.配置Flume文件：</strong>
agent1.sources=avro-source
agent1.channels=logger-channel
agent1.sinks=kafka-sink</p>
<p>#define source
agent1.sources.avro-source.type=avro
agent1.sources.avro-source.bind=0.0.0.0
agent1.sources.avro-source.port=41414</p>
<p>#define channel
agent1.channels.logger-channel.type=memory</p>
<p>#define sink
agent1.sinks.kafka-sink.type=org.apache.flume.sink.kafka.KafkaSink
agent1.sinks.kafka-sink.topic = flume-kafka-streaming-topic
agent1.sinks.kafka-sink.brokerList = hadoop:9092
agent1.sinks.kafka-sink.requiredAcks = 1
agent1.sinks.kafka-sink.batchSize = 20</p>
<p>agent1.sources.avro-source.channels=logger-channel
agent1.sinks.kafka-sink.channel=logger-channel</p>
<p><strong>启动flume-ng</strong></p>
<p>flume-ng agent <br>
--conf $FLUME_HOME/conf <br>
--conf-file $FLUME_HOME/conf/streaming.conf <br>
--name agent1 <br>
-Dflume.root.logger=INFO,console</p>
<p><strong>启动日志生产程序</strong>
bin/kafka-console-producer.sh –broker-list  hadoop:9092  –topic lume-kafka-streaming-topic</p>
<p>bin/kafka-console-consumer.sh –bootstrap-server hadoop02:9092 –topic flume-kafka-streaming-topic –from-beginning</p>
<p><strong>测试Flume</strong></p>
<p>bin/flume-ng avro-client -c conf -H 192.168.10.179 -p 41414 -F /app/log/test.log</p>
<p><strong>运行本地spark程序：</strong></p>
<p>def main(args: Array[String]): Unit = {
if (args.length &lt; 4) {
//Edit Configuration : 192.168.10.179:2181 test flume-kafka-streaming-topic 1
System.err.println(&quot;Usage: FlumeKafkaReceiverWordCount <zkQuorum> <group> <topics> <numThreads>&quot;)
System.exit(1)
}</p>
<p>val Array(zkQuorum, group, topics, numThreads) = args</p>
<p>val sparkConf = new SparkConf().setAppName(&quot;FlumeKafkaReceiverWordCount&quot;).setMaster(&quot;local[2]&quot;)
//val sparkConf = new SparkConf()</p>
<p>val ssc = new StreamingContext(sparkConf, Seconds(5))</p>
<p>val topicMap = topics.split(&quot;,&quot;).map((_, numThreads.toInt)).toMap</p>
<p>val messages = KafkaUtils.createStream(ssc, zkQuorum, group, topicMap)</p>
<p>messages.map(<em>.<em>2).flatMap(</em>.split(&quot; &quot;)).map((</em>, 1)).reduceByKey(_ + _).print()</p>
<p>ssc.start()
ssc.awaitTermination()
}</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spark]]></title>
        <id>https://huran111.github.io/post/spark</id>
        <link href="https://huran111.github.io/post/spark">
        </link>
        <updated>2019-09-29T04:31:43.000Z</updated>
        <content type="html"><![CDATA[<h3 id="spark是什么">Spark是什么</h3>
<pre><code>   Apache Spark 是专为大规模数据处理而设计的快速通用的计算引擎。Spark是UC Berkeley AMP lab (加州大学伯克利分校的AMP实验室)所开源的类Hadoop MapReduce的通用并行框架，Spark，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是——Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。
 Spark 是一种与 Hadoop 相似的开源集群计算环境，但是两者之间还存在一些不同之处，这些有用的不同之处使 Spark 在某些工作负载方面表现得更加优越，换句话说，Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载。
</code></pre>
<p>Spark 是在 Scala 语言中实现的，它将 Scala 用作其应用程序框架。与 Hadoop 不同，Spark 和 Scala 能够紧密集成，其中的 Scala 可以像操作本地集合对象一样轻松地操作分布式数据集。
尽管创建 Spark 是为了支持分布式数据集上的迭代作业，但是实际上它是对 Hadoop 的补充，可以在 Hadoop 文件系统中并行运行。通过名为 Mesos 的第三方集群框架可以支持此行为。Spark 由加州大学伯克利分校 AMP 实验室 (Algorithms, Machines, and People Lab) 开发，可用来构建大型的、低延迟的数据分析应用程序。</p>
<h3 id="什么是sparksql">什么是SparkSql?</h3>
<p>Spark SQL是Spark用来处理结构化数据的一个模块，它提供了2个编程抽象：DataFrame和DataSet，并且作为分布式SQL查询引擎的作用。</p>
<p>我们已经学习了Hive，它是将Hive SQL转换成MapReduce然后提交到集群上执行，大大简化了编写MapReduc的程序的复杂性，由于MapReduce这种计算模型执行效率比较慢。所有Spark SQL的应运而生，它是将Spark SQL转换成RDD，然后提交到集群执行，执行效率非常快！</p>
<h3 id="sparksql特点">SparkSql特点？</h3>
<ol>
<li>易整合
<img src="https://huran111.github.io/post-images/1569731678073.png" alt="">
2.统一的数据访问方式
<img src="https://huran111.github.io/post-images/1569731706084.png" alt="">
3.兼容Hive
<img src="https://huran111.github.io/post-images/1569731720818.png" alt="">
4.标准的数据连接
<img src="https://huran111.github.io/post-images/1569731734307.png" alt=""></li>
</ol>
<h3 id="什么是dataframe">什么是DataFrame?</h3>
<pre><code> 与RDD类似，DataFrame也是一个分布式数据容器。然而DataFrame更像传统数据库的二维表格，除了数据以外，还记录数据的结构信息，即schema。同时，与Hive类似，DataFrame也支持嵌套数据类型（struct、array和map）。从API易用性的角度上看，DataFrame API提供的是一套高层的关系操作，比函数式的RDD API要更加友好，门槛更低。
	 ![](https://huran111.github.io/post-images/1569731760042.png)
</code></pre>
<p>上图直观地体现了DataFrame和RDD的区别。左侧的RDD[Person]虽然以Person为类型参数，但Spark框架本身不了解Person类的内部结构。而右侧的DataFrame却提供了详细的结构信息，使得Spark SQL可以清楚地知道该数据集中包含哪些列，每列的名称和类型各是什么。DataFrame是为数据提供了Schema的视图。可以把它当做数据库中的一张表来对待，DataFrame也是懒执行的。性能上比RDD要高，主要原因：</p>
<p>优化的执行计划：查询计划通过Spark catalyst optimiser进行优化。</p>
<p><img src="https://huran111.github.io/post-images/1569731782276.png" alt="">
<img src="https://huran111.github.io/post-images/1569731797929.png" alt="">
注意：临时表是Session范围内的，Session退出后，表就失效了。如果想应用范围内有效，可以使用全局表。注意使用全局表时需要全路径访问，如：global_temp.people</p>
<h3 id="dsl风格语法">DSL风格语法</h3>
<p><img src="https://huran111.github.io/post-images/1569731843143.png" alt=""></p>
<p><img src="https://huran111.github.io/post-images/1569731858597.png" alt=""></p>
<h3 id="sparkstreaming是什么">SparkStreaming是什么？</h3>
<pre><code>Spark Streaming用于流式数据的处理。Spark Streaming支持的数据输入源很多，例如：Kafka、Flume、Twitter、ZeroMQ和简单的TCP套接字等等。数据输入后可以用Spark的高度抽象原语如：map、reduce、join、window等进行运算。而结果也能保存在很多地方，如HDFS，数据库等。
</code></pre>
<p><img src="https://huran111.github.io/post-images/1569731912291.png" alt="">
和Spark基于RDD的概念很相似，Spark Streaming使用离散化流(discretized stream)作为抽象表示，叫作DStream。DStream 是随时间推移而收到的数据的序列。在内部，每个时间区间收到的数据都作为 RDD 存在，而DStream是由这些RDD所组成的序列(因此得名“离散化”)。</p>
<h3 id="sparkstreaming特点">SparkStreaming特点</h3>
<p><img src="https://huran111.github.io/post-images/1569731935208.png" alt="">
<img src="https://huran111.github.io/post-images/1569731939464.png" alt="">
<img src="https://huran111.github.io/post-images/1569731943730.png" alt=""></p>
<p><img src="https://huran111.github.io/post-images/1569731953410.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Azkaban]]></title>
        <id>https://huran111.github.io/post/azkaban</id>
        <link href="https://huran111.github.io/post/azkaban">
        </link>
        <updated>2019-09-29T04:24:24.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="为什么需要工作流调度系统">为什么需要工作流调度系统</h3>
<ol>
<li>一个完整的数据分析系统通常都是由大量任务单元组成：shell脚本程序，java程序，mapreduce程序、hive脚本等</li>
<li>各任务单元之间存在时间先后及前后依赖关系</li>
<li>为了很好地组织起这样的复杂执行计划，需要一个工作流调度系统来调度执行</li>
<li>例如，我们可能有这样一个需求，某个业务系统每天产生20G原始数据，我们每天都要对其进行处理，处理步骤如下所示：
通过Hadoop先将原始数据同步到HDFS上；
借助MapReduce计算框架对原始数据进行计算，生成的数据以分区表的形式存储到多张Hive表中；
需要对Hive中多个表的数据进行JOIN处理，得到一个明细数据Hive大表；
将明细数据进行复杂的统计分析，得到结果报表信息；
需要将统计分析得到的结果数据同步到业务系统中，供业务调用使用。</li>
</ol>
]]></summary>
        <content type="html"><![CDATA[<h3 id="为什么需要工作流调度系统">为什么需要工作流调度系统</h3>
<ol>
<li>一个完整的数据分析系统通常都是由大量任务单元组成：shell脚本程序，java程序，mapreduce程序、hive脚本等</li>
<li>各任务单元之间存在时间先后及前后依赖关系</li>
<li>为了很好地组织起这样的复杂执行计划，需要一个工作流调度系统来调度执行</li>
<li>例如，我们可能有这样一个需求，某个业务系统每天产生20G原始数据，我们每天都要对其进行处理，处理步骤如下所示：
通过Hadoop先将原始数据同步到HDFS上；
借助MapReduce计算框架对原始数据进行计算，生成的数据以分区表的形式存储到多张Hive表中；
需要对Hive中多个表的数据进行JOIN处理，得到一个明细数据Hive大表；
将明细数据进行复杂的统计分析，得到结果报表信息；
需要将统计分析得到的结果数据同步到业务系统中，供业务调用使用。</li>
</ol>
<!-- more -->
<h3 id="azkaban与oozie对比">Azkaban与Oozie对比</h3>
<p>对市面上最流行的两种调度器，给出以下详细对比，以供技术选型参考。总体来说，ooize相比azkaban是一个重量级的任务调度系统，功能全面，但配置使用也更复杂。如果可以不在意某些功能的缺失，轻量级调度器azkaban是很不错的候选对象</p>
<h3 id="什么是azkaban">什么是Azkaban？</h3>
<p>Azkaban是由Linkedin开源的一个批量工作流任务调度器。用于在一个工作流内以一个特定的顺序运行一组工作和流程。Azkaban定义了一种KV文件格式来建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。</p>
<ul>
<li>它有如下功能特点：</li>
<li>Web用户界面</li>
<li>方便上传工作流</li>
<li>方便设置任务之间的关系</li>
<li>调度工作流</li>
<li>认证/授权(权限的工作)</li>
<li>能够杀死并重新启动工作流</li>
<li>模块化和可插拔的插件机制</li>
<li>项目工作区</li>
<li>工作流和任务的日志记录和审计
<img src="https://huran111.github.io/post-images/1569731319199.png" alt=""></li>
</ul>
<ol>
<li>AzkabanWebServer:是整个Azkaban工作流系统的主要管理者，它用户登录认证，负责project管理，定时执行工作流，跟踪工作流执行进度等一系列任务。</li>
<li>AzkabanExecutorServer:负责具体的工作流的提交，执行，他们通过mysql数据库来协调任务的执行</li>
<li>关系型数据库：存储大部分执行流状态</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[HDFS组成架构]]></title>
        <id>https://huran111.github.io/post/hdfs-zu-cheng-jia-gou</id>
        <link href="https://huran111.github.io/post/hdfs-zu-cheng-jia-gou">
        </link>
        <updated>2019-08-05T03:21:43.000Z</updated>
        <content type="html"><![CDATA[<h3 id="namenode">NameNode</h3>
<ul>
<li>就是Master，它是一个主管，管理者。
+ 管理HDFS的名称空间
+ 配置副本策略
+ 管理数据块映射信息
+ 处理客户端读写请求</li>
</ul>
<h3 id="datanode">DataNode</h3>
<ul>
<li>Slave ,NameNode下达命令，DataNode执行实际的操作。
<ul>
<li>存储实际的数据块</li>
<li>执行数据块的读写操作</li>
</ul>
</li>
</ul>
<h3 id="client-就是客户端">Client 就是客户端</h3>
<ul>
<li>文件切片，文件上传HDFS的时候，Client将文件切分成一个个的Block，然后进行上传</li>
<li>与NameNode交互，获取文件的位置信息</li>
<li>与DataNode交互，读取或者写入数据</li>
<li>Client提供一些命令来管理HDFS，比如NameNode 格式化</li>
<li>Client可以通过一些命令来访问HDFS,比如对HDFS增删查改操作</li>
</ul>
<h3 id="secondarynamenode-并非namenode的热备当namenode挂掉的时候它并不能替换namenode提供服务">SecondaryNameNode ：并非NameNode的热备，当NameNode挂掉的时候，它并不能替换NameNode提供服务</h3>
<ul>
<li>辅助NameNode,分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode；</li>
</ul>
<h3 id="hsfs的文件大小">HSFS的文件大小</h3>
<ul>
<li>老版本是64M,新版本是128M</li>
<li>HDFS的块设置的太小，会增加寻址时间，程序一直再找块的开始位置
<ul>
<li>如果块设置太大，从磁盘传输数据的时间就会明显大于定位这个块开始位置所需的时间，导致 程序处理这块数据的时候会非常慢。</li>
<li>块大小 主要取决的磁盘性能</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[享元模式]]></title>
        <id>https://huran111.github.io/post/xiang-yuan-mo-shi</id>
        <link href="https://huran111.github.io/post/xiang-yuan-mo-shi">
        </link>
        <updated>2019-07-17T06:43:43.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>享元模式能够解决重复对象的内存浪费问题，当系统中有大量相似的对象，需要缓冲池，不需要总是创建对象，可以从缓冲池里面拿。</li>
<li><img src="https://huran111.github.io/post-images/1563346983047.png" alt=""></li>
<li>FlyWeight是抽象的享元角色，它是产品的抽象类型，同时定义出对象的外部状态和内部状态</li>
<li>ConcreatFlyWeight是具体的享元角色，是具体的产品类，实现抽象角色相关业务。
+FlyWeightFactory享元工厂类，构建一个容器。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[程序变慢的分析]]></title>
        <id>https://huran111.github.io/post/cheng-xu-bian-man-de-fen-xi</id>
        <link href="https://huran111.github.io/post/cheng-xu-bian-man-de-fen-xi">
        </link>
        <updated>2019-07-04T06:50:19.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>top查看整机的CPU，和内存 平均负载</li>
<li><img src="https://huran111.github.io/post-images/1562223181383.png" alt=""></li>
<li><img src="https://huran111.github.io/post-images/1562223431688.png" alt=""></li>
<li>查看CPU-vmstat</li>
<li><img src="https://huran111.github.io/post-images/1562223534688.png" alt=""></li>
<li><img src="https://huran111.github.io/post-images/1562225055548.png" alt=""></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis-HyperLogLog]]></title>
        <id>https://huran111.github.io/post/redis-hyperloglog</id>
        <link href="https://huran111.github.io/post/redis-hyperloglog">
        </link>
        <updated>2019-06-27T09:46:06.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>
<p>redis提供了HyPerLogLog数据结构就就是用来解决这种统计问题，它提供了不精确的去重计数方案，虽然不是很精确，误差在0.81，但是已经可以满足上面UV统计需求了。</p>
</li>
<li>
<p>HyperLogLog 提供了两个指令 pfadd 和 pfcount，根据字面意义很好理解，一个是增加计数，一个是获取计数。pfadd 用法和 set 集合的 sadd 是一样的，来一个用户 ID，就将用户 ID 塞进去就是。pfcount 和 scard 用法是一样的，直接获取计数值。</p>
</li>
<li>
<p>HyperLogLog 除了上面的 pfadd 和 pfcount 之外，还提供了第三个指令 pfmerge，用于将多个 pf 计数值累加在一起形成一个新的 pf 值。</p>
</li>
<li>
<p>比如在网站中我们有两个内容差不多的页面，运营说需要这两个页面的数据进行合并。其中页面的 UV 访问量也需要合并，那这个时候 pfmerge 就可以派上用场了。</p>
</li>
<li>
<p><img src="https://huran111.github.io/post-images/1561629023523.png" alt=""></p>
</li>
<li>
<p>HyperLogLog 实现原理</p>
</li>
<li></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mysql有时会选错索引？]]></title>
        <id>https://huran111.github.io/post/mysql-you-shi-hui-xuan-cuo-suo-yin</id>
        <link href="https://huran111.github.io/post/mysql-you-shi-hui-xuan-cuo-suo-yin">
        </link>
        <updated>2019-06-27T01:29:24.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li><img src="https://huran111.github.io/post-images/1561599356731.png" alt=""></li>
<li>插入10W行数据，select * from t where a between 10000 and 20000; 查看执行计划</li>
<li><img src="https://huran111.github.io/post-images/1561599400795.png" alt=""></li>
<li>select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;</li>
<li>上面的语句，如果按照a进行查询，那么就是扫描a的前1000个值，然后取到对应的id，在到主键上查出每一行，然后根据B字段来过滤，显然需要扫描1000行。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[elasticsearch(一)]]></title>
        <id>https://huran111.github.io/post/elasticsearchyi</id>
        <link href="https://huran111.github.io/post/elasticsearchyi">
        </link>
        <updated>2019-06-24T06:24:37.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>查看节点健康情况</li>
<li>GET /_cat/health?v</li>
<li>绿色 一切正常集群功能齐全</li>
<li>黄色——所有数据可用，但有些副本尚未分配(集群功能完全)</li>
<li>红色——有些数据由于某种原因不可用(集群部分功能)</li>
<li>注意：当集群为红色时，它将继续从可用碎片中提供搜索请求，但是您可能需要尽快修复它，因为存在未分配的碎片。</li>
<li><img src="https://huran111.github.io/post-images/1561359907050.png" alt=""></li>
<li>查看所有的索引  GET /_cat/indices?v</li>
<li><img src="https://huran111.github.io/post-images/1561359922693.png" alt=""></li>
<li></li>
</ul>
]]></content>
    </entry>
</feed>