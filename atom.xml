<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://huran111.github.io</id>
    <title>大千世界</title>
    <updated>2019-05-31T04:45:29.989Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://huran111.github.io"/>
    <link rel="self" href="https://huran111.github.io/atom.xml"/>
    <subtitle>温故而知新-欢迎关注公众号《Java精选笔记》</subtitle>
    <logo>https://huran111.github.io/images/avatar.png</logo>
    <icon>https://huran111.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, 大千世界</rights>
    <entry>
        <title type="html"><![CDATA[工厂模式]]></title>
        <id>https://huran111.github.io/post/gong-han-mo-shi</id>
        <link href="https://huran111.github.io/post/gong-han-mo-shi">
        </link>
        <updated>2019-05-31T01:54:53.000Z</updated>
        <content type="html"><![CDATA[<pre><code>1.首先，我们明确一点，我们不应该针对实现编程，但是当我们每次使用new的时候，不正是在针对实现编程么？
</code></pre>
<p><img src="https://huran111.github.io/post-images/1559268374740.png" alt=""></p>
<ul>
<li>认识变化的方面
<img src="https://huran111.github.io/post-images/1559269101158.png" alt=""></li>
<li>但是压力就是来自于更多的披萨
<img src="https://huran111.github.io/post-images/1559269422754.png" alt=""></li>
<li>现在我们已经知道了哪里会发生变化，是时候开始封装了
<img src="https://huran111.github.io/post-images/1559270009251.png" alt=""></li>
<li>工厂处理创建对象的细节，一旦有了工厂，创建对象的时候，就叫工厂做一个，现在orderPizza()方法只是关心从工厂得到了一个披萨，而所有的类型披萨都实现了Pizza接口它们的bake(),cut(),box都可以通用。
<img src="https://huran111.github.io/post-images/1559271214457.png" alt=""></li>
<li>有人会问，这不还是一样么？只是把搬到另外一个对象里面罢了。
<ul>
<li>但是别忘了，SimplePizzaFactory可以有很多的客户，不仅仅只有orderPizza()这个方法，所以，当以后实现改变的时候，只需要修改这个类即可。</li>
<li>静态工厂不需要使用创建对象的方法来实例化对象，但是，它不能通过继承来改变创建方法的行为。</li>
</ul>
</li>
<li>重做披萨类
<img src="https://huran111.github.io/post-images/1559271869245.png" alt=""></li>
<li>定义简单工厂
<img src="https://huran111.github.io/post-images/1559272255417.png" alt=""></li>
<li>如果有很多不同的披萨加盟店，根据地域不同风味也不同，怎么办？
<ul>
<li>我么可以写出三种不同的工厂，分别负责创建不同区域的披萨。（VarPizzaFactory,Var2PizzaFactory,Var3PizzaFactory）
<img src="https://huran111.github.io/post-images/1559272741289.png" alt=""></li>
<li>我们把createPizza()方法放回到PizzaStore类中，把它设置为抽象。
<img src="https://huran111.github.io/post-images/1559273553779.png" alt="">
<ul>
<li>现在已经有了一个PizzaStore作为超类，让每个区域的类型都继承这个超类，各自实现制造披萨。
<img src="https://huran111.github.io/post-images/1559273831614.png" alt=""></li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[nginx基本配置与参数说明]]></title>
        <id>https://huran111.github.io/post/nginx-ji-ben-pei-zhi-yu-can-shu-shuo-ming</id>
        <link href="https://huran111.github.io/post/nginx-ji-ben-pei-zhi-yu-can-shu-shuo-ming">
        </link>
        <updated>2019-05-30T08:40:30.000Z</updated>
        <content type="html"><![CDATA[<p>#运行用户
user nobody;
#启动进程,通常设置成和cpu的数量相等
worker_processes  1;</p>
<p>#全局错误日志及PID文件
#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;</p>
<p>#pid        logs/nginx.pid;</p>
<p>#工作模式及连接数上限
events {
#epoll是多路复用IO(I/O Multiplexing)中的一种方式,
#仅用于linux2.6以上内核,可以大大提高nginx的性能
use   epoll;</p>
<pre><code>#单个后台worker process进程的最大并发链接数    
worker_connections  1024;

# 并发总数是 worker_processes 和 worker_connections 的乘积
# 即 max_clients = worker_processes * worker_connections
# 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4  为什么
# 为什么上面反向代理要除以4，应该说是一个经验值
# 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000
# worker_connections 值的设置跟物理内存大小有关
# 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数
# 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右
# 我们来看看360M内存的VPS可以打开的文件句柄数是多少：
# $ cat /proc/sys/fs/file-max
# 输出 34336
# 32000 &lt; 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内
# 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置
# 使得并发总数小于操作系统可以打开的最大文件数目
# 其实质也就是根据主机的物理CPU和内存进行配置
# 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。
# ulimit -SHn 65535
</code></pre>
<p>}</p>
<p>http {
#设定mime类型,类型由mime.type文件定义
include    mime.types;
default_type  application/octet-stream;
#设定日志格式
log_format  main  '$remote_addr - <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mi>e</mi><mi>m</mi><mi>o</mi><mi>t</mi><msub><mi>e</mi><mi>u</mi></msub><mi>s</mi><mi>e</mi><mi>r</mi><mo>[</mo></mrow><annotation encoding="application/x-tex">remote_user [</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">m</span><span class="mord mathdefault">o</span><span class="mord mathdefault">t</span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">[</span></span></span></span>time_local] &quot;<span class='katex-error' title='ParseError: KaTeX parse error: Double superscript at position 34: …               &#039;̲'>request&quot; &#039;
                      &#039;</span>status <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>b</mi><mi>o</mi><mi>d</mi><msub><mi>y</mi><mi>b</mi></msub><mi>y</mi><mi>t</mi><mi>e</mi><msub><mi>s</mi><mi>s</mi></msub><mi>e</mi><mi>n</mi><mi>t</mi><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">body_bytes_sent &quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">b</span><span class="mord mathdefault">o</span><span class="mord mathdefault">d</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord">&quot;</span></span></span></span>http_referer&quot; '
'&quot;<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mi>t</mi><mi>t</mi><msub><mi>p</mi><mi>u</mi></msub><mi>s</mi><mi>e</mi><msub><mi>r</mi><mi>a</mi></msub><mi>g</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi mathvariant="normal">&quot;</mi><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">http_user_agent&quot; &quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">h</span><span class="mord mathdefault">t</span><span class="mord mathdefault">t</span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord">&quot;</span><span class="mord">&quot;</span></span></span></span>http_x_forwarded_for&quot;';</p>
<pre><code>access_log  logs/access.log  main;

#sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，
#对于普通应用，必须设为 on,
#如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，
#以平衡磁盘与网络I/O处理速度，降低系统的uptime.
sendfile     on;
#tcp_nopush     on;

#连接超时时间
#keepalive_timeout  0;
keepalive_timeout  65;
tcp_nodelay     on;

#开启gzip压缩
gzip  on;
gzip_disable &quot;MSIE [1-6].&quot;;

#设定请求缓冲
client_header_buffer_size    128k;
large_client_header_buffers  4 128k;


#设定虚拟主机配置
server {
    #侦听80端口
    listen    80;
    #定义使用 www.nginx.cn访问
    server_name  www.nginx.cn;

    #定义服务器的默认网站根目录位置
    root html;

    #设定本虚拟主机的访问日志
    access_log  logs/nginx.access.log  main;

    #默认请求
    location / {
        
        #定义首页索引文件的名称
        index index.php index.html index.htm;   

    }

    # 定义错误提示页面
    error_page   500 502 503 504 /50x.html;
    location = /50x.html {
    }

    #静态文件，nginx自己处理
    location ~ ^/(images|javascript|js|css|flash|media|static)/ {
        
        #过期30天，静态文件不怎么更新，过期可以设大一点，
        #如果频繁更新，则可以设置得小一点。
        expires 30d;
    }

    #禁止访问 .htxxx 文件
        location ~ /.ht {
        deny all;
    }

}
</code></pre>
<p>}</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Nginx（一）]]></title>
        <id>https://huran111.github.io/post/nginxyi</id>
        <link href="https://huran111.github.io/post/nginxyi">
        </link>
        <updated>2019-05-30T08:11:59.000Z</updated>
        <content type="html"><![CDATA[<h4 id="nginx是什么">Nginx是什么</h4>
<ul>
<li>
<p>Nginx是一个代理服务器
**一个完整的代理请求：</p>
</li>
<li>
<p>客户端先与代理服务器创建连接</p>
</li>
<li>
<p>然后根据代理服务器所使用的协议，请求对目标服务器创建连接，或获取目标服务器的指定资源。
**Nginx的特定</p>
</li>
<li>
<p>跨平台</p>
</li>
<li>
<p>配置异常简单</p>
</li>
<li>
<p>阻塞、高并发连接：数据复制时，磁盘I/O的第一阶段是非阻塞的。官方测试能够支撑5万并发连接，在实际生产环境中跑到2～3万并发连接数</p>
</li>
<li>
<p>事件驱动：通信机制采用epoll模型，支持更大的并发连接</p>
</li>
<li>
<p>master/worker结构：一个master进程，生成一个或多个worker进程</p>
</li>
<li>
<p>内存消耗小：处理大并发的请求内存消耗非常小。在3万并发连接下，开启的10个Nginx 进程才消耗150M内存（15M*10=150M）</p>
</li>
<li>
<p>节省带宽：支持 GZIP 压缩，可以添加浏览器本地缓存的 Header 头。</p>
</li>
<li>
<p>稳定性高：用于反向代理，宕机的概率微乎其微
**什么是事件驱动？</p>
</li>
<li>
<p>非阻塞通过不断检查事件的状态来判断是否进行读写操作，这样带来的开销很大。</p>
</li>
<li>
<p>通过异步非阻塞的事件处理机制，Nginx实现由进程循环处理多个准备好的事件，从而实现高并发和轻量级</p>
</li>
<li>
<p>。他们提供了一种机制，让你可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。这种机制解决了我们上面两个问题。 （select/poll/epoll/kqueue）</p>
</li>
<li>
<p>以epoll为例：当事件没有准备好时，就放入epoll(队列)里面。如果有事件准备好了，那么就去处理；如果事件返回的是EAGAIN，那么继续将其放入epoll里面。从而，只要有事件准备好了，我们就去处理她，只有当所有时间都没有准备好时，才在epoll里面等着。这样 ，我们就可以并发处理大量的并发了，当然，这里的并发请求，是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，切换也是因为异步事件未准备好，而主动让出的。这里的切换是没有任何代价，你可以理 解为循环处理多个准备好的事件，事实上就是这样的
**Nginx内部的模型
<img src="https://huran111.github.io/post-images/1559205024191.png" alt=""></p>
</li>
<li>
<p>nginx在启动后，会有一个master进程和多个worker进程。master进程主要用来管理worker进程，包含：接收来自外界的信号，向各worker进程发送信号，监控 worker进程的运行状态,当worker进程退出后(异常情况下)，会自动重新启动新的worker进程。而基本的网 络事件，则是放在worker进程中来处理了 。多个worker进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的 。一个请求，只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。 worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致，这里面的原因与nginx的进程模型以及事件处理模型是分不开的</p>
</li>
<li>
<p>Master接收到信号以后怎样进行处理（./nginx -s reload ）?首先master进程在接到信号后，会先重新加载配置文件，然后再启动新的进程，并向所有老的进程发送信号，告诉他们可以光荣退休了。新的进程在启动后，就开始接收新的请求，而老的进程在收到来自 master的信号后，就不再接收新的请求，并且在当前进程中的所有未处理完的请求处理完成后，再退出 .</p>
</li>
<li>
<p>worker进程又是如何处理请求的呢？我们前面有提到，worker进程之间是平等的，每个进程，处理请求的机会也是一样的。当我们提供80端口的http服务时，一个连接请求过来，每个进程都有可能处理这个连接，怎么做到的呢？首先，每个worker进程都是从master 进程fork(分配)过来，在master进程里面，先建立好需要listen的socket之后，然后再fork出多个worker进程，这样每个worker进程都可以去accept这个socket(当然不是同一个socket，只是每个进程的这个socket会监控在同一个ip地址与端口，这个在网络协议里面是允许的)。一般来说，当一个连接进来后，所有在accept在这个socket上面的进程，都会收到通知，而只有一个进程可以accept这个连接，其它的则accept失败，这是所谓的惊群现象。当然，nginx也不会视而不见，所以nginx提供了一个accept_mutex这个东西，从名字上，我们可以看这是一个加在accept上的一把共享锁。有了这把锁之后，同一时刻，就只会有一个进程在accpet连接，这样就不会有惊群问题了。accept_mutex是一个可控选项，我们可以显示地关掉，默认是打开的。当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由worker进程来处理，而且只在一个worker进程中处理。
**Nginx是如何处理一个请求</p>
</li>
<li>
<p>首先，nginx在启动时，会解析配置文件，得到需要监听的端口与ip地址，然后在nginx的master进程里面，先初始化好这个监控的socket(创建socket，设置addrreuse等选项，绑定到指定的ip地址端口，再listen)，然后再fork(一个现有进程可以调用fork函数创建一个 新进程。由fork创建的新进程被称为子进程 )出多个子进程出来，然后子进程会竞争accept新的连接。此时，客户端就可以向nginx发起连接了。当客户端与nginx进行三次握手，与nginx建立好一个连接后，此时，某一个子进程会accept成功，得到这个建立好的连接的 socket，然后创建nginx对连接的封装，即ngx_connection_t结构体。接着，设置读写事件处理函数并添加读写事件来与客户端进行数据的交换。最后，nginx或客户端来主动关掉连接，到此，一个连接就寿终正寝了。</p>
</li>
</ul>
<p>当然，nginx也是可以作为客户端来请求其它server的数据的（如upstream模块），此时，与其它server创建的连接，也封装在ngx_connection_t中。作为客户端，nginx先获取一个ngx_connection_t结构体，然后创建socket，并设置socket的属性（ 比如非阻塞）。然后再通过添加读写事件，调用connect/read/write来调用连接，最后关掉连接，并释放ngx_connection_t。</p>
<p>nginx在实现时，是通过一个连接池来管理的，每个worker进程都有一个独立的连接池，连接池的大小是worker_connections。这里的连接池里面保存的其实不是真实的连接，它只是一个worker_connections大小的一个ngx_connection_t结构的数组。并且，nginx会通过一个链表free_connections来保存所有的空闲ngx_connection_t，每次获取一个连接时，就从空闲连接链表中获取一个，用完后，再放回空闲连接链表里面。</p>
<p>在这里，很多人会误解worker_connections这个参数的意思，认为这个值就是nginx所能建立连接的最大值。其实不然，这个值是表示每个worker进程所能建立连接的最大值，所以，一个nginx能建立的最大连接数，应该是worker_connections * worker_processes。当然 ，这里说的是最大连接数，对于HTTP请求本地资源来说，能够支持的最大并发数量是worker_connections * worker_processes，而如果是HTTP作为反向代理来说，最大并发数量应该是worker_connections * worker_processes/2。因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。
**Nginx的特点</p>
<ul>
<li>nginx代理和后端web服务器间无需长连接；</li>
<li>接收用户请求是异步的，即先将用户请求全部接收下来，再一次性发送后后端web服务器，极大的减轻后端web服务器的压力</li>
<li>发送响应报文时，是边接收来自后端web服务器的数据，边发送给客户端的</li>
<li>网络依赖型低。NGINX对网络的依赖程度非常低，理论上讲，只要能够ping通就可以实施负载均衡，而且可以有效区分内网和外网流量</li>
<li>支持服务器检测。NGINX能够根据应用服务器处理页面返回的状态码、超时信息等检测服务器是否出现故障，并及时返回错误的请求重新提交到其它节点上</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[生成环境多线程使用]]></title>
        <id>https://huran111.github.io/post/sheng-cheng-huan-jing-duo-xian-cheng-shi-yong</id>
        <link href="https://huran111.github.io/post/sheng-cheng-huan-jing-duo-xian-cheng-shi-yong">
        </link>
        <updated>2019-05-29T03:29:01.000Z</updated>
        <content type="html"><![CDATA[<h3 id="threadpoolexecutor简介">ThreadPoolExecutor简介：</h3>
<p><img src="https://huran111.github.io/post-images/1559100567965.png" alt="">
int corePoolSize：该线程池中核心线程数最大值</p>
<p>核心线程：线程池新建线程的时候，如果当前线程总数小于corePoolSize，则新建的是核心线程，如果超过corePoolSize，则新建的是非核心线程核心线程默认情况下会一直存活在线程池中，即使这个核心线程啥也不干(闲置状态)。
如果指定ThreadPoolExecutor的allowCoreThreadTimeOut这个属性为true，那么核心线程如果不干活(闲置状态)的话，超过一定时间(时长下面参数决定)，就会被销毁掉</p>
<p>int maximumPoolSize： 该线程池中线程总数最大值</p>
<p>线程总数 = 核心线程数 + 非核心线程数。</p>
<p>long keepAliveTime：该线程池中非核心线程闲置超时时长</p>
<p>一个非核心线程，如果不干活(闲置状态)的时长超过这个参数所设定的时长，就会被销毁掉，如果设置allowCoreThreadTimeOut = true，则会作用于核心线程。</p>
<p>TimeUnit unit：keepAliveTime的单位</p>
<p>TimeUnit是一个枚举类型，其包括：
NANOSECONDS ： 1微毫秒 = 1微秒 / 1000
MICROSECONDS ： 1微秒 = 1毫秒 / 1000
MILLISECONDS ： 1毫秒 = 1秒 /1000
SECONDS ： 秒
MINUTES ： 分
HOURS ： 小时
DAYS ： 天
BlockingQueue workQueue：该线程池中的任务队列：维护着等待执行的Runnable对象</p>
<p>当所有的核心线程都在干活时，新添加的任务会被添加到这个队列中等待处理，如果队列满了，则新建非核心线程执行任务。</p>
<ul>
<li>SynchronousQueue：这个队列接收到任务的时候，会直接提交给线程处理，而不保留它，如果所有线程都在工作怎么办？那就新建一个线程来处理这个任务！所以为了保证不出现&lt;线程数达到了maximumPoolSize而不能新建线程&gt;的错误，使用这个类型队列的时候，maximumPoolSize一般指定成Integer.MAX_VALUE，即无限大</li>
<li>LinkedBlockingQueue：这个队列接收到任务的时候，如果当前线程数小于核心线程数，则新建线程(核心线程)处理任务；如果当前线程数等于核心线程数，则进入队列等待。由于这个队列没有最大值限制，即所有超过核心线程数的任务都将被添加到队列中，这也就导致了maximumPoolSize的设定失效，因为总线程数永远不会超过corePoolSize</li>
<li>ArrayBlockingQueue：可以限定队列的长度，接收到任务的时候，如果没有达到corePoolSize的值，则新建线程(核心线程)执行任务，如果达到了，则入队等候，如果队列已满，则新建线程(非核心线程)执行任务，又如果总线程数到了maximumPoolSize，并且队列也满了，则发生错误</li>
<li>DelayQueue：队列内元素必须实现Delayed接口，这就意味着你传进去的任务必须先实现Delayed接口。这个队列接收到任务时，首先先入队，只有达到了指定的延时时间，才会执行任务</li>
<li>ThreadFactory threadFactory：创建线程的方式，这是一个接口，你new他的时候需要实现他的Thread newThread(Runnable r)方法，一般用不上。</li>
<li>RejectedExecutionHandler handler：这玩意儿就是抛出异常专用的，比如上面提到的两个错误发生了，就会由这个handler抛出异常</li>
<li>线程数量未达到corePoolSize，则新建一个线程(核心线程)执行任务，线程数量达到了corePools，则将任务移入队列等待，队列已满，新建线程(非核心线程)执行任务，队列已满，总线程数又达到了maximumPoolSize，就会由(RejectedExecutionHandler)抛出异常</li>
</ul>
<h3 id="countdownlatch">CountDownLatch</h3>
<p>CountDownLatch是在java1.5被引入的，跟它一起被引入的并发工具类还有CyclicBarrier、Semaphore、ConcurrentHashMap和BlockingQueue，它们都存在于java.util.concurrent包下。CountDownLatch这个类能够使一个线程等待其他线程完成各自的工作后再执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。</p>
<p>CountDownLatch是通过一个计数器来实现的，计数器的初始值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就会减1。当计数器值到达0时，它表示所有的线程已经完成了任务，然后在闭锁上等待的线程就可以恢复执行任务.</p>
<h3 id="future和callable">Future和Callable:</h3>
<p>Callable接口代表一段可以调用并返回结果的代码;Future接口表示异步任务，是还没有完成的任务给出的未来结果。所以说Callable用于产生结果，Future用于获取结果。</p>
<p>Callable接口使用泛型去定义它的返回类型。Executors类提供了一些有用的方法在线程池中执行Callable内的任务。由于Callable任务是并行的（并行就是整体看上去是并行的，其实在某个时间点只有一个线程在执行），我们必须等待它返回的结果。
java.util.concurrent.Future对象为我们解决了这个问题。在线程池提交Callable任务后返回了一个Future对象，使用它可以知道Callable任务的状态和得到Callable返回的执行结果。Future提供了get()方法让我们可以等待Callable结束并获取它的执行结果。</p>
<h3 id="semaphore">semaphore:</h3>
<p>Semaphore是一种在多线程环境下使用的设施，该设施负责协调各个线程，以保证它们能够正确、合理的使用公共资源的设施，也是操作系统中用于控制进程同步互斥的量。
**案例：
<img src="https://huran111.github.io/post-images/1559100823289.png" alt="">
<img src="https://huran111.github.io/post-images/1559100829756.png" alt="">
<img src="https://huran111.github.io/post-images/1559100837942.png" alt="">
<img src="https://huran111.github.io/post-images/1559100843372.png" alt="">
案例二：
<img src="https://huran111.github.io/post-images/1559100853506.png" alt="">
<img src="https://huran111.github.io/post-images/1559100858927.png" alt="">
可见耗时为：
<img src="https://huran111.github.io/post-images/1559100867625.png" alt="">
案例三：使用多线程
<img src="https://huran111.github.io/post-images/1559100877491.png" alt="">
<img src="https://huran111.github.io/post-images/1559100891871.png" alt="">
耗时： 很明显 快了太多
<img src="https://huran111.github.io/post-images/1559100903945.png" alt="">
在并发数目较多的场景下可以加入Semaphore:
<img src="https://huran111.github.io/post-images/1559100913600.png" alt="">
<img src="https://huran111.github.io/post-images/1559100919322.png" alt="">
扩展：开发小技巧
<img src="https://huran111.github.io/post-images/1559100931806.png" alt="">
<img src="https://huran111.github.io/post-images/1559100938350.png" alt="">
<img src="https://huran111.github.io/post-images/1559100944837.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring Cloud微服务-Eureka+Ribbon]]></title>
        <id>https://huran111.github.io/post/spring-cloud-wei-fu-wu-eurekaribbon</id>
        <link href="https://huran111.github.io/post/spring-cloud-wei-fu-wu-eurekaribbon">
        </link>
        <updated>2019-05-29T03:18:40.000Z</updated>
        <content type="html"><![CDATA[<p>Spring Cloud是什么？</p>
<p>（1）云计算？不是</p>
<p>(2) 依赖于Spring Boot</p>
<p>(3)快速构建分布式系统的工具集-全集桶</p>
<p>2.关于Spring Cloud的版本？</p>
<ul>
<li>
<p>大部分spring软件的版本是以：主版本.次版本.增量版本.里程碑版本的形式命名</p>
</li>
<li>
<p>Spring Cloud特点</p>
<p>+（1）约定优于配置</p>
<p>+（2）开箱即用、快速启动</p>
<p>+（3）适用于各种环境 --PC Serve ---云环境--容器(Docker)</p>
<p>+（4）轻量级的组件-Eureka-服务发现</p>
<ul>
<li>
<p>(5) 组件的支持很丰富，功能很齐全-配置中心--注册中心--智能路由</p>
</li>
<li>
<p>(6) 选型中立--服务发现--Eureka-Zookeeper-Consul</p>
</li>
</ul>
</li>
</ul>
<ol start="4">
<li>需要的技术储备</li>
</ol>
<p>(1)Java/Scala/Groovy...</p>
<p>(2)构建工具--Maven--Gradle</p>
<p>(3)Spring Boot</p>
<p>服务提供者与服务消费者:
<img src="https://huran111.github.io/post-images/1559099978253.png" alt="">
**务发现组件：Eureka
1:什么事Eureka?</p>
<p>(1)Eureka来自生产环境</p>
<p>(2)Spring Cloud对Eureka支持很好</p>
<p>Eureka是Netflix开发的服务发现框架，本身是一个基于REST的服务，主要用于定位运行在AWS域中的中间层服务，以达到负载均衡和中间层服务故障转移的目的。Spring Cloud将它集成在其子项目spring-cloud-netflix中，以实现Spring Cloud的服务发现功能。</p>
<p>1:Eureka 原理
<img src="https://huran111.github.io/post-images/1559100003664.png" alt="">
<img src="https://huran111.github.io/post-images/1559100009417.png" alt="">
上图是来自Eureka官方的架构图，大致描述了Eureka集群的工作过程。由于图比较复杂，可能比较难看懂，这边用通俗易懂的语言翻译一下：
Application Service 就相当于本书中的服务提供者（用户微服务），
Application Client就相当于本书中的服务消费者（电影微服务）；</p>
<ul>
<li>
<p>Make Remote Call，可以简单理解为调用RESTful的接口；</p>
</li>
<li>
<p>us-east-1c、us-east-1d等是zone，它们都属于us-east-1这个region；
由图可知，Eureka包含两个组件：Eureka Server 和 Eureka Client。
Eureka Server提供服务注册服务，各个节点启动后，会在Eureka Server中进行注册，这样Eureka Server中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到。
--- Eureka Client是一个Java客户端，用于简化与Eureka Server的交互，客户端同时也具备一个内置的、使用轮询（round-robin）负载算法的负载均衡器。</p>
</li>
</ul>
<p>在应用启动后，将会向Eureka Server发送心跳（默认周期为30秒）。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，Eureka Server将会从服务注册表中把这个服务节点移除（默认90秒）。
Eureka Server之间将会通过复制的方式完成数据的同步。（详见Eureka高可用章节）
Eureka还提供了客户端缓存的机制，即使所有的Eureka Server都挂掉，客户端依然可以利用缓存中的信息消费其他服务的API。
综上，Eureka通过心跳检测、健康检查、客户端缓存等机制，确保了系统的高可用性、灵活性和可伸缩性。
实现Euraka Server和Client: 相关关代码已经放到GitHub上：
https://github.com/huran111
<img src="https://huran111.github.io/post-images/1559100120537.png" alt="">
可以看到 2个服务提供者一个消费者。</p>
<p>学习可参考官方文档：https://cloud.spring.io/spring-cloud-static/spring-cloud-netflix/2.1.0.RC3/single/spring-cloud-netflix.html#netflix-eureka-client-starter 其余百度都扯淡
<img src="https://huran111.github.io/post-images/1559100134858.png" alt="">
如下我们开启4个微服务，服务名称分别为：user-producter:8900,user-producter:8901,user-producter-2:7900,user-producter-2:7901
一个消费端：user-consumer-ribbon
注意请看官方文档这句话：
<img src="https://huran111.github.io/post-images/1559100152997.png" alt="">
大致意思就是，配置RibbonClient的时候不能放在和启动类同一个包下。否则会覆盖所有RibbonClient其他配置策略。
解决方法是自定义在注解，进行排除。
<img src="https://huran111.github.io/post-images/1559100202907.png" alt="">
<img src="https://huran111.github.io/post-images/1559100208028.png" alt="">
<img src="https://huran111.github.io/post-images/1559100214788.png" alt="">
<img src="https://huran111.github.io/post-images/1559100221099.png" alt="">
<img src="https://huran111.github.io/post-images/1559100230496.png" alt="">
Eureka默认是xml，可在方法是声明为JSON格式，可以看到接口分别请求了四个服务。这里我们其请求了8次：结果如下
<img src="https://huran111.github.io/post-images/1559100241470.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql事务隔离]]></title>
        <id>https://huran111.github.io/post/mysql-shi-wu-ge-chi</id>
        <link href="https://huran111.github.io/post/mysql-shi-wu-ge-chi">
        </link>
        <updated>2019-05-29T03:09:31.000Z</updated>
        <content type="html"><![CDATA[<p>隔离性和隔离级别</p>
<p>事务，ACID，即原子性，一致性，隔离性，持久性。</p>
<p>当数据库上有多个事务同时执行的时候，就可能出现脏读，不可重复读，幻读的问题，就有了隔离的感念。</p>
<p>SQL标准的事务隔离级别包括：读未提交，读提交，可重复读，和串行化。</p>
<p>读未提交：一个事务还没提交时，它做的变更就能被别的事务看到。</p>
<p>读提交：一个事务提交之后，它做的变更才会被其他事务看到。</p>
<p>可重复读：一个事务执行过程中看到的数据，总是跟这个事务在启动的时候看到的数据是一致的，在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</p>
<p>串行化：对于同一行记录，写会加锁，读会加锁，当出现读写冲突的时候，后访问的事务必须等待前一个事务执行完成，才能继续执行。</p>
<p>栗子，如下语句</p>
<pre><code>       create table T(c int) engine=InnoDB;
       insert into T(c) values(1);
				 ![](https://huran111.github.io/post-images/1559099397233.png)
</code></pre>
<p>若隔离级别是读未提交，则V1的值就是2，这时候事务B虽然还没有提交，但是结果已经被A看到了，因此，V2,V3也都是2</p>
<p>若隔离级别是读提交，则V1是1，V2的值是2，事务B的更新在提交后才能被A看到，所以，V3的值也是2</p>
<p>若隔离级别是可重复读，则V1,V2是1，V3是2，之所以V2还是1，遵循的就是这个要求：事务在执行期间看到数据前后必须是一致的</p>
<p>若隔离级别是串行化，则在事务B执行将1改成2的时候，会被锁住，直到事务A提交后，事务B才可以继续执行，所以从A的角度看，V1,V2值是1，V3值是2</p>
<p>在实现上，数据流里面对创建一个视图，访问的时候以视图的逻辑结果为准，在可重复读，隔离级别下，这个视图在事务启动时创建的，整个事务存在期间都用这个视图，在读提交隔离级别下，这个视图是在每个sql语句开始执行的时候创建的，这里需要注意的是，读未提交隔离级别下直接返回记录上的最新值，没有视图概念，而串行化直接用加锁的方式来避免并行访问。
**事务隔离的实现
以可重读读为例：</p>
<p>在MySql中，实际上每条记录在更新的时候都会同时记录一条回滚操作，记录上的最新值，通过回滚操作，都可以得到前一个状态的值。</p>
<p>假设一个值从1被按照顺序改成 了2，3，4在回滚日志里面就会有类似下面的记录。
<img src="https://huran111.github.io/post-images/1559099440259.png" alt="">
当前值是4，但是查询这条记录的时候，不同时刻启动是事务会有不同的read-view,如图，在视图A,B,C里面，这一个记录的值分别是1，2，4，同一条记录在系统中可以存多个版本，就是数据库的多版本并发控制，对于read-viewA，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。</p>
<p>回滚日志在不需要的时候才删除，系统会判断，当没有事务在需要用到这写回滚日志的时候，就会删除。</p>
<p>在Mysql5.5以及以前的版本，回滚日志是跟数据字典放在ibdata文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小，长事务会占用锁资源，可能拖垮整个库。
**事务的启动方式
Mysql事务启动方式有一下几种：</p>
<p>显式的启动事务语句，begin或者start  transaction，配套的提交语句是commit，回滚语句是rollback。</p>
<p>set autocommit=0 这个命令会将这个线程的自动提交关闭，意味着如果你执行一个select语句，这个事务就启动了，而且并不会自动提交，这个事务持续存在直到你主动执行commit或者rollback语句，或者断开连接。</p>
<p>有些客户端连接框架会默认连接成功后先执行一个set autocommit=0的I命令，这就导致下来查询都在事务中，如果是长连接，就导致了意外的长事务。因此，建议使用set autocommit=1，通过显式语句方式来启动事务。</p>
<p>可以在information_schema库的 innodb_trx这个表中查询长事务
**为什么不建议使用长事务？以mysql默认级别可重复读为例。
比如，在某个时刻（今天上午9：00点）开启了一个事务（对于可重复隔离别，此时一个视图 read-viewA也创建了）这是一个很长的事务.....</p>
<p>事务A在今天早上9：20的时候，查询了一个记录R1的一个字段f1的值为1......</p>
<p>今天早上9：25的时候，一个事务B（随之而来的read-viewB）也被开启了，它更新了R1.f1的值为2（同时也创建了一个由2到1 的回滚日志），这是一个短事务，事务随后就被commit了。</p>
<p>到了下午六点，长事务A还没有呗commit,为了保证事务在执行期间看到的数据在前后必须是一致的。那些老的事务视图，回滚日志就必须存在了，这就占用了大量的存储空间.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql-索引（2）]]></title>
        <id>https://huran111.github.io/post/mysql-suo-yin-2</id>
        <link href="https://huran111.github.io/post/mysql-suo-yin-2">
        </link>
        <updated>2019-05-28T10:24:06.000Z</updated>
        <content type="html"><![CDATA[<p>在下面的表中，执行select * from T where k between 3 and 5,需要执行几次树的搜索操作，会扫描多少行？
<img src="https://huran111.github.io/post-images/1559039084517.png" alt="">
<img src="https://huran111.github.io/post-images/1559039090493.png" alt="">
这条SQL查询语句的执行流程为</p>
<p>在A索引树上找到A=3的记录，取得ID=300</p>
<p>再到ID索引树查到ID=300对应的A3</p>
<p>再回到A索引数取下一个值5，取得ID=600</p>
<p>再回到ID索引树查到ID=600对应的A5</p>
<p>在K索引树取下一个值A=6,不满足条件，循环结束</p>
<p>在这个过程中，回到主键索引树搜索的过程，为回表。这个例子中查询结果所需要的数据只在主键索引上有，所以不得不回表，那么，有没有可能经过索引优化，避免回表的过程呢？
**覆盖索引
如果执行的语句为select id from T where k between 3 and 5 这时只需要查询Id的值，而ID的值已经在A索引树上了，因此直接提供查询结果，不需要回表，在这个查询里面，索引 A已经“覆盖”了我们的查询需求，我们称为覆盖索引。</p>
<p>由于覆盖索引减少了树的搜索次数，性能显著提升，所以使用覆盖索引是一个常用的性能优化手段。
栗子：</p>
<p>学生表定义
<img src="https://huran111.github.io/post-images/1559039165559.png" alt="">
学号是学生的唯一标识，如果有根据学号查询学生的信息，只要在学号这个字段上建立索引就够了，在建立一个（学号，姓名）的联合索引，是不是有点浪费空间？</p>
<p>B+树这种索引结构，可以利用索引的最左前缀，来定位记录。
可以看到，索引项是按照索引定义里面出现的字段顺序排序的。</p>
<p>当查到所有名字是张三的人时，可以快速定位到ID4，饭后向后遍历得到所有需要的结果。</p>
<p>当你查到所有名字第一个字为张的人，SQL语句为‘张%’,也能用上这个索引</p>
<p>只要满足最左前缀，就可以利用索引加速检索，这个前缀索引可以使联合索引的最左N个字段，也可以是字符串索引的最左M个字符。</p>
<p>在建立联合索引的时候，如何安排索引内的字符顺序？</p>
<p>当有(a,b)两个联合索引后，一般就不需要单独在a上建立索引了，因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。</p>
<p>那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Elastic-Job——分布式定时任务框架实战]]></title>
        <id>https://huran111.github.io/post/elastic-job-fen-bu-shi-ding-shi-ren-wu-kuang-jia-shi-zhan</id>
        <link href="https://huran111.github.io/post/elastic-job-fen-bu-shi-ding-shi-ren-wu-kuang-jia-shi-zhan">
        </link>
        <updated>2019-05-28T04:42:02.000Z</updated>
        <content type="html"><![CDATA[<p>Elastic-Job是ddframe中dd-job的作业模块中分离出来的分布式弹性作业框架。去掉了和dd-job中的监控和ddframe接入规范部分。该项目基于成熟的开源产品Quartz和Zookeeper及其客户端Curator进行二次开发。 ddframe其他模块也有可独立开源的部分，之前当当曾开源过dd-soa的基石模块DubboX。 项目开源地址：https://github.com/dangdangdotcom/elastic-job
Elastic-Job是ddframe中dd-job的作业模块中分离出来的分布式弹性作业框架。去掉了和dd-job中的监控和ddframe接入规范部分。该项目基于成熟的开源产品Quartz和Zookeeper及其客户端Curator进行二次开发。
**Elastic-Job主要功能
**定时任务： 基于成熟的定时任务作业框架Quartz cron表达式执行定时任务
作业注册中心： 基于Zookeeper和其客户端Curator实现的全局作业注册控制中心。用于注册，控制和协调分布式作业执行。</p>
<p>**作业分片： 将一个任务分片成为多个小任务项在多服务器上同时执行。</p>
<p>**弹性扩容缩容： 运行中的作业服务器崩溃，或新增加n台作业服务器，作业框架将在下次作业执行前重新分片，不影响当前作业执行。</p>
<p>**支持多种作业执行模式： 支持OneOff，Perpetual和SequencePerpetual三种作业模式。</p>
<p>**失效转移： 运行中的作业服务器崩溃不会导致重新分片，只会在下次作业启动时分片。启用失效转移功能可以在本次作业执行过程中，监测其他作业服务器空闲，抓取未完成的孤儿分片项执行。</p>
<p>**运行时状态收集： 监控作业运行时状态，统计最近一段时间处理的数据成功和失败数量，记录作业上次运行开始时间，结束时间和下次运行时间。</p>
<p>**作业停止，恢复和禁用：用于操作作业启停，并可以禁止某作业运行（上线时常用）。</p>
<p>被错过执行的作业重触发：自动记录错过执行的作业，并在上次作业完成后自动触发。可参考Quartz的misfire。</p>
<p>**多线程快速处理数据：使用多线程处理抓取到的数据，提升吞吐量。</p>
<p>**幂等性：重复作业任务项判定，不重复执行已运行的作业任务项。由于开启幂等性需要监听作业运行状态，对瞬时反复运行的作业对性能有较大影响。</p>
<p>**容错处理：作业服务器与Zookeeper服务器通信失败则立即停止作业运行，防止作业注册中心将失效的分片分项配给其他作业服务器，而当前作业服务器仍在执行任务，导致重复执行。</p>
<p>**Spring支持：支持spring容器，自定义命名空间，支持占位符。
** 运维平台：提供运维界面，可以管理作业和注册中心。</p>
<h3 id="目录结构说明">目录结构说明</h3>
<p>lastic-job-core</p>
<p>elastic-job核心模块，只通过Quartz和Curator就可执行分布式作业。</p>
<p>elastic-job-spring</p>
<p>elastic-job对spring支持的模块，包括命名空间，依赖注入，占位符等。</p>
<p>elastic-job-console</p>
<p>elastic-job web控制台，可将编译之后的war放入tomcat等servlet容器中使用。</p>
<p>elastic-job-example</p>
<p>使用例子。</p>
<p>elastic-job-test</p>
<p>测试elastic-job使用的公用类，使用方无需关注。
下面进行实战案例：
本案例是SpringBoot+Jpa+Zookeeper+Elastic-job进行讲解。案例代码已经放到本人GitHub上面，地址为：https://github.com/huran111/elastic-job 可自行下载运行。
(1)项目准备。</p>
<p>1.1 新建三个一样的spring boot项目，在实际生产中 分别部署在三台服务器上。
<img src="https://huran111.github.io/post-images/1559018656404.png" alt="">
1.2 安装zookeeper，安装非常简单，可百度，实际生产可部署三台zookeeper集群做高可用，本项目安装一台作为讲解用。
1.3 引入jar.
<img src="https://huran111.github.io/post-images/1559018719225.png" alt="">
1.4 配置参数
application.yum
<img src="https://huran111.github.io/post-images/1559018739375.png" alt="">
application-dev.yum  具体配置在GitHub上。
<img src="https://huran111.github.io/post-images/1559018752312.png" alt="">
<img src="https://huran111.github.io/post-images/1559018762594.png" alt="">
1.5 配置Job.xml
1.5.1 在启动类上面加入注解
<img src="https://huran111.github.io/post-images/1559018787851.png" alt="">
1.5.2 Job.xml详细配置
<img src="https://huran111.github.io/post-images/1559018803717.png" alt="">
这里三台服务器分成了9片
<img src="https://huran111.github.io/post-images/1559018950785.png" alt="">
(2).数据准备。<br>
实体类：
<img src="https://huran111.github.io/post-images/1559018964639.png" alt="">
（3）生成100条数据，实际场景数据可能会更多（1000万条也是有可能的）。
<img src="https://huran111.github.io/post-images/1559018985931.png" alt="">
(4)运行测试用例可以看到数据已经插入成功，其中random字段作为随机数，不是业务字段，只来后序的分片处理。
<img src="https://huran111.github.io/post-images/1559019000076.png" alt="">
（5）验证
5.1 启动服务器server-01，指定10秒后执行。
可以看到分片数量：0,1,2,3,4,5,6,7,8
<img src="https://huran111.github.io/post-images/1559019023412.png" alt="">
5.2启动服务器server-02，同样指定10秒后执行。
可以看到分片数量：0,1,2,3,4，8
<img src="https://huran111.github.io/post-images/1559019036213.png" alt="">
而此时server-01的分片数量自动变为：4,5,6,7
<img src="https://huran111.github.io/post-images/1559019045770.png" alt="">
5.3 下面我们在启动第三台服务器server-03:
可以看到分片数量：6,7,8
<img src="https://huran111.github.io/post-images/1559019054861.png" alt="">
而此时server-01和server-02有什么变化呢？
<img src="https://huran111.github.io/post-images/1559019064557.png" alt="">
可以看到server-01变成了3,4,5，server-02变成了 0,1,2
<img src="https://huran111.github.io/post-images/1559019079952.png" alt="">
5.4 下面我们关闭一台机器，比如server-03:
<img src="https://huran111.github.io/post-images/1559019089909.png" alt="">
再来查看分片数量;
<img src="https://huran111.github.io/post-images/1559019100068.png" alt="">
什么情况？ 这是基于zookeeper的调度算法，来进行自动分片的，当有一台机器挂了或者加入了会自动分配数量。从而实现分布式调度以及处理大数据量的数据。 分片策略可以看：https://blog.csdn.net/tanga842428/article/details/52689119这篇文章</p>
<p>真正的企业里面怎么用的呢？
还记得刚才模拟的100条数据吧 。正常企业中可能会有几百万或者千万的数据，这里来模拟100条数据怎么分布式处理。</p>
<p>Job类编写如下：实现SimpleJob接口
<img src="https://huran111.github.io/post-images/1559019122344.png" alt="">
分别启动三台服务：查看处理数据情况
--------------------------------------------server-01---------------------------------------------</p>
<p><img src="https://huran111.github.io/post-images/1559019131188.png" alt="">
------------------------------------------------server-02------------------------------------------</p>
<p><img src="https://huran111.github.io/post-images/1559019139364.png" alt="">
------------------------------------------------server-03----------------------------------------
<img src="https://huran111.github.io/post-images/1559019146096.png" alt=""></p>
<p>可以看到 三台服务分别处理了这100条数据，这就是分布式调度的意思。在大数据处理中，可以结合该框架，将同一个项目部署在多台机器上，同属处理大数据量的数据，再结合多线程技术,大大增加了效率。</p>
<p>扩展：如果数据多达千万级，此时对mysql的性能影响会很大，此时建议使用ElasticSearch分布式搜索引擎存储读写频率高的数据。主要定时业务可使用Redis作为分布式锁避免重复执行。</p>
<p>---------------------------------------------控制搭建-----------------------------------------------
控制台手动触发任务：
<img src="https://huran111.github.io/post-images/1559019158960.png" alt="">
<img src="https://huran111.github.io/post-images/1559019165136.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql-索引（1）]]></title>
        <id>https://huran111.github.io/post/mysql1-suo-yin</id>
        <link href="https://huran111.github.io/post/mysql1-suo-yin">
        </link>
        <updated>2019-05-28T03:38:22.000Z</updated>
        <content type="html"><![CDATA[<p>InnoBD使用的B+树索引模型，所以数据都是存储在B+树中的。</p>
<p>每一个索引在InnoDB里面对应一棵B+树。</p>
<p>假如我们有一个主键列为Id的表，表中有字段A,在A上有索引。</p>
<pre><code>create table T(

id int primary key, 

A int not null, 

name varchar(16),

index (A))engine=InnoDB;
</code></pre>
<p>表中A1-A5的（ID,A）值分别为(100,1),(200,2),(300,3),(500,6)和(600,6),两棵数的示例图入下：
<img src="https://huran111.github.io/post-images/1559038934132.png" alt="">
从图中看出，根据叶子节点内容，索引类型分为主键索引和非主键索引。</p>
<p>主键索引的叶子节点内容是整行数据，在InnoDB里，主键索引也称之为聚簇索引。</p>
<p>非主键索引的叶子节点内容是主键的值，在InnoBD里，非主键索引也被称为二级索引。</p>
<p>那么，主键和普通索引的查询有什么区别呢？</p>
<p>如果语句为select *  from T where id=600,也就是主键查询方式，则只需要搜索ID这棵B+树。</p>
<p>如果语句为select * fromT where a=6,也就是普通索引查询方式，则先搜索A索引树,得到ID的值为600，再到ID索引树搜索一次，该过程称之为回表。</p>
<p>因此，我们在日常开发中，尽量使用主键查询，避免回表。
**索引的维护
B+树维护了索引的有序性，在插入新的值的时候需要做必要的维护，以上图为例，如果插入 一个ID的值为700，则只需要在A5的记录后面插入一个新记录，如果插入ID的值为400，就相对麻烦了，需要逻辑上移动后面的数据，空出位置。</p>
<p>如果A5所在的数据页满了，根据B+数的算法，这时候需要申请一个新的数据 页，然后移动部分数据过去，这个过程为页分裂，这种情况下，性能会受到影响。</p>
<p>除了性能，页分裂还影响数据页的利用率，原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约50%。</p>
<p>当然有分裂就有合并，系统会将数据也合并。</p>
<p>基于上述，哪些场景下应该使用自增主键，而哪些场景下不应该？</p>
<p>插入新记录的时候可以不知道ID,系统会获取当前ID最大值加1作为下一条记录的Id值。自增主键的插入数据模式，符合 递增插入的场景，每次插入一条新记录，都是追加操作，都不涉及到移动其他记录，也不会触发叶子节点的分裂。</p>
<p>假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？</p>
<p>主键长度越小，普通索引的叶子节点就越小，由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节
什么场景下适合业务字段做主键？</p>
<p>只有一个索引</p>
<p>改索引必须是唯一索引</p>
<p>KV场景</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Thread]]></title>
        <id>https://huran111.github.io/post/java-duo-xian-cheng-bi-ji</id>
        <link href="https://huran111.github.io/post/java-duo-xian-cheng-bi-ji">
        </link>
        <updated>2019-05-28T03:12:43.000Z</updated>
        <content type="html"><![CDATA[<p>线程的概念：
线程是程序中执行的线程。Java虚拟机允许应用程序同时运行多个执行线程。每个线程都有一个优先级。优先级较高的线程优先于优先级较低的线程执行。每个线程也可以标记为守护进程，也可以不标记为守护进程。当在某个线程中运行的代码创建一个新线程对象时，新线程的优先级初始设置为创建线程的优先级，并且只有当创建线程是一个守护进程时，新线程才是守护进程。当Java虚拟机启动时，通常有一个非守护进程线程(它通常调用一些指定类的main方法)。Java虚拟机继续执行线程，直到下列情况之一发生:
+ 调用了类运行时的退出方法，并且安全管理器允许执行退出操作。
+ 不是守护进程线程的所有线程都已死亡，要么从对run方法的调用返回，要么抛出一个在run方法之外传播的异常。</p>
<hr>
<ul>
<li>线程的创建方式
<ul>
<li>继承Thread类</li>
<li>实现Rubbable接口</li>
<li>实现Callable接口</li>
</ul>
</li>
<li>线程的六种状态
<ul>
<li>NEW 尚未启动的线程处于此状态。
<ul>
<li>线程尚未启动的时候的状态 也就是NEW出来的时候。</li>
</ul>
</li>
<li>RUNNABLE 在 java虚拟机中执行的线程处于此状态。
<ul>
<li>可运行线程的线程状态。 可运行状态的线程正在Java虚拟机中执行，但它可能正在等待来自操作系统（例如处理器）的其他资源。</li>
</ul>
</li>
<li>BLOCKED  等待监视器锁的阻塞线程的线程状态。
<ul>
<li>一个线程的线程状态阻塞等待监视器锁定。 处于阻塞状态的线程正在等待监视器锁定进入同步块/方法，或者在调用Object.wait后重新输入同步的块/方法。</li>
</ul>
</li>
<li>WAITING 正在等待另一个线程执行特定动作的线程处于此状态。
<ul>
<li>等待线程的线程状态 由于调用以下方法之一，线程处于等待状态：
<ul>
<li>Object.wait没有超时</li>
<li>Thread.join没有超时</li>
<li>LockSupport.park</li>
<li>等待状态的线程正在等待另一个线程执行特定的动作。 例如，已经在对象上调用Object.wait()线程正在等待另一个线程调用该对象上Object.notify() Object.notifyAll()或。 调用Thread.join()的线程正在等待指定的线程终止</li>
</ul>
</li>
</ul>
</li>
<li>TIMED_WAITING 正在等待另一个线程执行动作达到指定等待时间的线程处于此状态。
<ul>
<li>具有指定等待时间的等待线程的线程状态。 线程处于定时等待状态，因为在指定的正等待时间内调用以下方法之一：
<ul>
<li>Thread.sleep</li>
<li>Object.wait与超时</li>
<li>Thread.join与超时</li>
<li>LockSupport.parkNanos</li>
<li>LockSupport.parkUntil</li>
</ul>
</li>
</ul>
</li>
<li>TEARMINATED 已退出的线程处于此状态。
<ul>
<li>终止线程的线程状态。 线程已完成执行。</li>
</ul>
</li>
<li>ThreadFactory
<ul>
<li>根据需要创建新线程的对象。 使用线程工厂可以删除new Thread的硬连线 ，使应用程序能够使用特殊的线程子类，优先级等。</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
</feed>