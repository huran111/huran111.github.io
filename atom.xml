<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://huran111.github.io</id>
    <title>胡的博客</title>
    <updated>2019-09-29T04:39:39.840Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://huran111.github.io"/>
    <link rel="self" href="https://huran111.github.io/atom.xml"/>
    <subtitle>知其然，知其所以然</subtitle>
    <logo>https://huran111.github.io/images/avatar.png</logo>
    <icon>https://huran111.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, 胡的博客</rights>
    <entry>
        <title type="html"><![CDATA[Spark]]></title>
        <id>https://huran111.github.io/post/spark</id>
        <link href="https://huran111.github.io/post/spark">
        </link>
        <updated>2019-09-29T04:31:43.000Z</updated>
        <content type="html"><![CDATA[<h3 id="spark是什么">Spark是什么</h3>
<pre><code>   Apache Spark 是专为大规模数据处理而设计的快速通用的计算引擎。Spark是UC Berkeley AMP lab (加州大学伯克利分校的AMP实验室)所开源的类Hadoop MapReduce的通用并行框架，Spark，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是——Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的MapReduce的算法。
 Spark 是一种与 Hadoop 相似的开源集群计算环境，但是两者之间还存在一些不同之处，这些有用的不同之处使 Spark 在某些工作负载方面表现得更加优越，换句话说，Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载。
</code></pre>
<p>Spark 是在 Scala 语言中实现的，它将 Scala 用作其应用程序框架。与 Hadoop 不同，Spark 和 Scala 能够紧密集成，其中的 Scala 可以像操作本地集合对象一样轻松地操作分布式数据集。
尽管创建 Spark 是为了支持分布式数据集上的迭代作业，但是实际上它是对 Hadoop 的补充，可以在 Hadoop 文件系统中并行运行。通过名为 Mesos 的第三方集群框架可以支持此行为。Spark 由加州大学伯克利分校 AMP 实验室 (Algorithms, Machines, and People Lab) 开发，可用来构建大型的、低延迟的数据分析应用程序。</p>
<h3 id="什么是sparksql">什么是SparkSql?</h3>
<p>Spark SQL是Spark用来处理结构化数据的一个模块，它提供了2个编程抽象：DataFrame和DataSet，并且作为分布式SQL查询引擎的作用。</p>
<p>我们已经学习了Hive，它是将Hive SQL转换成MapReduce然后提交到集群上执行，大大简化了编写MapReduc的程序的复杂性，由于MapReduce这种计算模型执行效率比较慢。所有Spark SQL的应运而生，它是将Spark SQL转换成RDD，然后提交到集群执行，执行效率非常快！</p>
<h3 id="sparksql特定">SparkSql特定？</h3>
<ol>
<li>易整合
<img src="https://huran111.github.io/post-images/1569731678073.png" alt="">
2.统一的数据访问方式
<img src="https://huran111.github.io/post-images/1569731706084.png" alt="">
3.兼容Hive
<img src="https://huran111.github.io/post-images/1569731720818.png" alt="">
4.标准的数据连接
<img src="https://huran111.github.io/post-images/1569731734307.png" alt=""></li>
</ol>
<h3 id="什么是dataframe">什么是DataFrame?</h3>
<pre><code> 与RDD类似，DataFrame也是一个分布式数据容器。然而DataFrame更像传统数据库的二维表格，除了数据以外，还记录数据的结构信息，即schema。同时，与Hive类似，DataFrame也支持嵌套数据类型（struct、array和map）。从API易用性的角度上看，DataFrame API提供的是一套高层的关系操作，比函数式的RDD API要更加友好，门槛更低。
	 ![](https://huran111.github.io/post-images/1569731760042.png)
</code></pre>
<p>上图直观地体现了DataFrame和RDD的区别。左侧的RDD[Person]虽然以Person为类型参数，但Spark框架本身不了解Person类的内部结构。而右侧的DataFrame却提供了详细的结构信息，使得Spark SQL可以清楚地知道该数据集中包含哪些列，每列的名称和类型各是什么。DataFrame是为数据提供了Schema的视图。可以把它当做数据库中的一张表来对待，DataFrame也是懒执行的。性能上比RDD要高，主要原因：</p>
<p>优化的执行计划：查询计划通过Spark catalyst optimiser进行优化。</p>
<p><img src="https://huran111.github.io/post-images/1569731782276.png" alt="">
<img src="https://huran111.github.io/post-images/1569731797929.png" alt="">
注意：临时表是Session范围内的，Session退出后，表就失效了。如果想应用范围内有效，可以使用全局表。注意使用全局表时需要全路径访问，如：global_temp.people</p>
<h3 id="dsl风格语法">DSL风格语法</h3>
<p><img src="https://huran111.github.io/post-images/1569731843143.png" alt=""></p>
<p><img src="https://huran111.github.io/post-images/1569731858597.png" alt=""></p>
<h3 id="sparkstreaming是什么">SparkStreaming是什么？</h3>
<pre><code>Spark Streaming用于流式数据的处理。Spark Streaming支持的数据输入源很多，例如：Kafka、Flume、Twitter、ZeroMQ和简单的TCP套接字等等。数据输入后可以用Spark的高度抽象原语如：map、reduce、join、window等进行运算。而结果也能保存在很多地方，如HDFS，数据库等。
</code></pre>
<p><img src="https://huran111.github.io/post-images/1569731912291.png" alt="">
和Spark基于RDD的概念很相似，Spark Streaming使用离散化流(discretized stream)作为抽象表示，叫作DStream。DStream 是随时间推移而收到的数据的序列。在内部，每个时间区间收到的数据都作为 RDD 存在，而DStream是由这些RDD所组成的序列(因此得名“离散化”)。</p>
<h3 id="sparkstreaming特点">SparkStreaming特点</h3>
<p><img src="https://huran111.github.io/post-images/1569731935208.png" alt="">
<img src="https://huran111.github.io/post-images/1569731939464.png" alt="">
<img src="https://huran111.github.io/post-images/1569731943730.png" alt=""></p>
<p><img src="https://huran111.github.io/post-images/1569731953410.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Azkaban]]></title>
        <id>https://huran111.github.io/post/azkaban</id>
        <link href="https://huran111.github.io/post/azkaban">
        </link>
        <updated>2019-09-29T04:24:24.000Z</updated>
        <summary type="html"><![CDATA[<h3 id="为什么需要工作流调度系统">为什么需要工作流调度系统</h3>
<ol>
<li>一个完整的数据分析系统通常都是由大量任务单元组成：shell脚本程序，java程序，mapreduce程序、hive脚本等</li>
<li>各任务单元之间存在时间先后及前后依赖关系</li>
<li>为了很好地组织起这样的复杂执行计划，需要一个工作流调度系统来调度执行</li>
<li>例如，我们可能有这样一个需求，某个业务系统每天产生20G原始数据，我们每天都要对其进行处理，处理步骤如下所示：
通过Hadoop先将原始数据同步到HDFS上；
借助MapReduce计算框架对原始数据进行计算，生成的数据以分区表的形式存储到多张Hive表中；
需要对Hive中多个表的数据进行JOIN处理，得到一个明细数据Hive大表；
将明细数据进行复杂的统计分析，得到结果报表信息；
需要将统计分析得到的结果数据同步到业务系统中，供业务调用使用。</li>
</ol>
]]></summary>
        <content type="html"><![CDATA[<h3 id="为什么需要工作流调度系统">为什么需要工作流调度系统</h3>
<ol>
<li>一个完整的数据分析系统通常都是由大量任务单元组成：shell脚本程序，java程序，mapreduce程序、hive脚本等</li>
<li>各任务单元之间存在时间先后及前后依赖关系</li>
<li>为了很好地组织起这样的复杂执行计划，需要一个工作流调度系统来调度执行</li>
<li>例如，我们可能有这样一个需求，某个业务系统每天产生20G原始数据，我们每天都要对其进行处理，处理步骤如下所示：
通过Hadoop先将原始数据同步到HDFS上；
借助MapReduce计算框架对原始数据进行计算，生成的数据以分区表的形式存储到多张Hive表中；
需要对Hive中多个表的数据进行JOIN处理，得到一个明细数据Hive大表；
将明细数据进行复杂的统计分析，得到结果报表信息；
需要将统计分析得到的结果数据同步到业务系统中，供业务调用使用。</li>
</ol>
<!-- more -->
<h3 id="azkaban与oozie对比">Azkaban与Oozie对比</h3>
<p>对市面上最流行的两种调度器，给出以下详细对比，以供技术选型参考。总体来说，ooize相比azkaban是一个重量级的任务调度系统，功能全面，但配置使用也更复杂。如果可以不在意某些功能的缺失，轻量级调度器azkaban是很不错的候选对象</p>
<h3 id="什么是azkaban">什么是Azkaban？</h3>
<p>Azkaban是由Linkedin开源的一个批量工作流任务调度器。用于在一个工作流内以一个特定的顺序运行一组工作和流程。Azkaban定义了一种KV文件格式来建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。</p>
<ul>
<li>它有如下功能特点：</li>
<li>Web用户界面</li>
<li>方便上传工作流</li>
<li>方便设置任务之间的关系</li>
<li>调度工作流</li>
<li>认证/授权(权限的工作)</li>
<li>能够杀死并重新启动工作流</li>
<li>模块化和可插拔的插件机制</li>
<li>项目工作区</li>
<li>工作流和任务的日志记录和审计
<img src="https://huran111.github.io/post-images/1569731319199.png" alt=""></li>
</ul>
<ol>
<li>AzkabanWebServer:是整个Azkaban工作流系统的主要管理者，它用户登录认证，负责project管理，定时执行工作流，跟踪工作流执行进度等一系列任务。</li>
<li>AzkabanExecutorServer:负责具体的工作流的提交，执行，他们通过mysql数据库来协调任务的执行</li>
<li>关系型数据库：存储大部分执行流状态</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[HDFS组成架构]]></title>
        <id>https://huran111.github.io/post/hdfs-zu-cheng-jia-gou</id>
        <link href="https://huran111.github.io/post/hdfs-zu-cheng-jia-gou">
        </link>
        <updated>2019-08-05T03:21:43.000Z</updated>
        <content type="html"><![CDATA[<h3 id="namenode">NameNode</h3>
<ul>
<li>就是Master，它是一个主管，管理者。
+ 管理HDFS的名称空间
+ 配置副本策略
+ 管理数据块映射信息
+ 处理客户端读写请求</li>
</ul>
<h3 id="datanode">DataNode</h3>
<ul>
<li>Slave ,NameNode下达命令，DataNode执行实际的操作。
<ul>
<li>存储实际的数据块</li>
<li>执行数据块的读写操作</li>
</ul>
</li>
</ul>
<h3 id="client-就是客户端">Client 就是客户端</h3>
<ul>
<li>文件切片，文件上传HDFS的时候，Client将文件切分成一个个的Block，然后进行上传</li>
<li>与NameNode交互，获取文件的位置信息</li>
<li>与DataNode交互，读取或者写入数据</li>
<li>Client提供一些命令来管理HDFS，比如NameNode 格式化</li>
<li>Client可以通过一些命令来访问HDFS,比如对HDFS增删查改操作</li>
</ul>
<h3 id="secondarynamenode-并非namenode的热备当namenode挂掉的时候它并不能替换namenode提供服务">SecondaryNameNode ：并非NameNode的热备，当NameNode挂掉的时候，它并不能替换NameNode提供服务</h3>
<ul>
<li>辅助NameNode,分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode；</li>
</ul>
<h3 id="hsfs的文件大小">HSFS的文件大小</h3>
<ul>
<li>老版本是64M,新版本是128M</li>
<li>HDFS的块设置的太小，会增加寻址时间，程序一直再找块的开始位置
<ul>
<li>如果块设置太大，从磁盘传输数据的时间就会明显大于定位这个块开始位置所需的时间，导致 程序处理这块数据的时候会非常慢。</li>
<li>块大小 主要取决的磁盘性能</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[享元模式]]></title>
        <id>https://huran111.github.io/post/xiang-yuan-mo-shi</id>
        <link href="https://huran111.github.io/post/xiang-yuan-mo-shi">
        </link>
        <updated>2019-07-17T06:43:43.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>享元模式能够解决重复对象的内存浪费问题，当系统中有大量相似的对象，需要缓冲池，不需要总是创建对象，可以从缓冲池里面拿。</li>
<li><img src="https://huran111.github.io/post-images/1563346983047.png" alt=""></li>
<li>FlyWeight是抽象的享元角色，它是产品的抽象类型，同时定义出对象的外部状态和内部状态</li>
<li>ConcreatFlyWeight是具体的享元角色，是具体的产品类，实现抽象角色相关业务。
+FlyWeightFactory享元工厂类，构建一个容器。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[程序变慢的分析]]></title>
        <id>https://huran111.github.io/post/cheng-xu-bian-man-de-fen-xi</id>
        <link href="https://huran111.github.io/post/cheng-xu-bian-man-de-fen-xi">
        </link>
        <updated>2019-07-04T06:50:19.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>top查看整机的CPU，和内存 平均负载</li>
<li><img src="https://huran111.github.io/post-images/1562223181383.png" alt=""></li>
<li><img src="https://huran111.github.io/post-images/1562223431688.png" alt=""></li>
<li>查看CPU-vmstat</li>
<li><img src="https://huran111.github.io/post-images/1562223534688.png" alt=""></li>
<li><img src="https://huran111.github.io/post-images/1562225055548.png" alt=""></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[redis-HyperLogLog]]></title>
        <id>https://huran111.github.io/post/redis-hyperloglog</id>
        <link href="https://huran111.github.io/post/redis-hyperloglog">
        </link>
        <updated>2019-06-27T09:46:06.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>
<p>redis提供了HyPerLogLog数据结构就就是用来解决这种统计问题，它提供了不精确的去重计数方案，虽然不是很精确，误差在0.81，但是已经可以满足上面UV统计需求了。</p>
</li>
<li>
<p>HyperLogLog 提供了两个指令 pfadd 和 pfcount，根据字面意义很好理解，一个是增加计数，一个是获取计数。pfadd 用法和 set 集合的 sadd 是一样的，来一个用户 ID，就将用户 ID 塞进去就是。pfcount 和 scard 用法是一样的，直接获取计数值。</p>
</li>
<li>
<p>HyperLogLog 除了上面的 pfadd 和 pfcount 之外，还提供了第三个指令 pfmerge，用于将多个 pf 计数值累加在一起形成一个新的 pf 值。</p>
</li>
<li>
<p>比如在网站中我们有两个内容差不多的页面，运营说需要这两个页面的数据进行合并。其中页面的 UV 访问量也需要合并，那这个时候 pfmerge 就可以派上用场了。</p>
</li>
<li>
<p><img src="https://huran111.github.io/post-images/1561629023523.png" alt=""></p>
</li>
<li>
<p>HyperLogLog 实现原理</p>
</li>
<li></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[mysql有时会选错索引？]]></title>
        <id>https://huran111.github.io/post/mysql-you-shi-hui-xuan-cuo-suo-yin</id>
        <link href="https://huran111.github.io/post/mysql-you-shi-hui-xuan-cuo-suo-yin">
        </link>
        <updated>2019-06-27T01:29:24.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li><img src="https://huran111.github.io/post-images/1561599356731.png" alt=""></li>
<li>插入10W行数据，select * from t where a between 10000 and 20000; 查看执行计划</li>
<li><img src="https://huran111.github.io/post-images/1561599400795.png" alt=""></li>
<li>select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;</li>
<li>上面的语句，如果按照a进行查询，那么就是扫描a的前1000个值，然后取到对应的id，在到主键上查出每一行，然后根据B字段来过滤，显然需要扫描1000行。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[elasticsearch(一)]]></title>
        <id>https://huran111.github.io/post/elasticsearchyi</id>
        <link href="https://huran111.github.io/post/elasticsearchyi">
        </link>
        <updated>2019-06-24T06:24:37.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>查看节点健康情况</li>
<li>GET /_cat/health?v</li>
<li>绿色 一切正常集群功能齐全</li>
<li>黄色——所有数据可用，但有些副本尚未分配(集群功能完全)</li>
<li>红色——有些数据由于某种原因不可用(集群部分功能)</li>
<li>注意：当集群为红色时，它将继续从可用碎片中提供搜索请求，但是您可能需要尽快修复它，因为存在未分配的碎片。</li>
<li><img src="https://huran111.github.io/post-images/1561359907050.png" alt=""></li>
<li>查看所有的索引  GET /_cat/indices?v</li>
<li><img src="https://huran111.github.io/post-images/1561359922693.png" alt=""></li>
<li></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql事务隔离]]></title>
        <id>https://huran111.github.io/post/mysql-shi-wu-ge-chi2</id>
        <link href="https://huran111.github.io/post/mysql-shi-wu-ge-chi2">
        </link>
        <updated>2019-06-21T02:45:58.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>ACID:原子性，一致性，隔离性，持久性</li>
<li>脏读，不可重复读，幻读</li>
<li>隔离级别：读未提交，读提交，可重复读，串行化
<ul>
<li>读未提交：一个事务还没提交时，它做的变化就能被其他事务看到</li>
<li>读提交：一个事务提交之后，它做的变化才能被其他事务看到</li>
<li>可重复读：一个事务执行的过程中看到的数据，总是跟这个事务在启动时候看到的数据是一致的。 当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</li>
<li>串行化：写会加锁，读会加锁。</li>
<li>例子：创建一个Innodb的表</li>
<li><img src="https://huran111.github.io/post-images/1561085875549.png" alt=""></li>
<li><img src="https://huran111.github.io/post-images/1561085903921.png" alt=""></li>
<li>查看当前会话的隔离级别</li>
<li><img src="https://huran111.github.io/post-images/1561086181670.png" alt=""></li>
<li>查看系统的隔离级别</li>
<li><img src="https://huran111.github.io/post-images/1561086214373.png" alt=""></li>
<li>设置会话的隔离级别，隔离级别由低到高设置依次为:</li>
<li>set session transaction isolation level read uncommitted;</li>
<li>set session transaction isolation level read committed;</li>
<li>set session transaction isolation level repeatable read;</li>
<li>set session transaction isolation level serializable;</li>
</ul>
</li>
<li><strong>(1) 将当前会话的隔离级别设置为读未提交</strong></li>
<li><img src="https://huran111.github.io/post-images/1561087288815.png" alt=""></li>
<li><strong>(2) 将当前会话的隔离级别设置为读提交</strong></li>
<li><img src="https://huran111.github.io/post-images/1561087817551.png" alt=""></li>
<li><strong>(3) 将当前会话的隔离级别设置为可重复读</strong></li>
<li><img src="https://huran111.github.io/post-images/1561088709444.png" alt=""></li>
<li><img src="https://huran111.github.io/post-images/1561088933068.png" alt="">
<strong>事务隔离的实现</strong></li>
<li>在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。</li>
<li><img src="https://huran111.github.io/post-images/1561096570337.png" alt=""></li>
<li>事务的启动方式</li>
<li>1 显示启动  start transaction -commint 回滚是rollback</li>
<li>2 set autocommit=0 将线程的自动提交关闭，意味着手动执行一个select 事务就开启了 ，而且并不会自动提交。建议set autocommit=1</li>
<li>也可以用 commit work and chain 意思是提交事务并自动进入下一个事务。</li>
<li>查询长事务：select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60</li>
</ul>
<h3 id="事务到底是隔离还是不隔离">事务到底是隔离还是不隔离</h3>
<ul>
<li><img src="https://huran111.github.io/post-images/1561377409110.png" alt=""></li>
<li>Mysql里面视图有两个概念
<ul>
<li>一个是view,查询定义的虚拟表。</li>
<li>另一个是Innodb在实现MVCC用到的一致性读视图，由于支持RC和RR的实现。</li>
<li>快照在MVCC是如何工作的?
<ul>
<li>在可重复读级别下，事务在启动的时候就拍了个快照，基于整个库的（并没有拷贝数据）</li>
<li>InnoDB每个事务都有一个唯一的事务Id，transaction id。在事务开始的时候想InnoDB中事务系统申请的，严格递增。</li>
<li>每行数据也有多个版本。每次事务更新数据，就会生成一个版本。把这个事务id赋值给新的数据版本的事务id，旧版本保留。</li>
<li>下图就是记录一个被多个事务连续更新后的状态</li>
<li><img src="https://huran111.github.io/post-images/1561424334675.png" alt=""></li>
<li>InnoDB是如何定义那个&quot;100G&quot;的快照的，按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果，但是之后，这个事务执行期间，其他事务的更新对它不可见。</li>
<li>实现上，InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，正在活跃的事务ID,就是值启动了还没有提交。</li>
<li>一个数据版本，对于一个视图来说，除了自己的更新总是可以见的，另外有三种情况
<ul>
<li>版本未提交，不可见</li>
<li>版本已经提交，但是是在视图创建后提交的，不可见</li>
<li>版本已经提交，而且实在视图创建前提交的，可见</li>
<li>InnoDB的行数据有多个版本，每个数据版本都有自己的row_trx_id,每个事务或者语句有自己的一致性视图，普通查询语句是一致性读，一致性读会根据row_trx_id和一致性视图确定数据版本的可见性。</li>
<li>对于可重复读，查询只承认在事务启动前就已经提交完成的数据。
+ 对于读提交，查询只承认在语句启动前就已经提交完成的数据。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[一条sql是如何更新的]]></title>
        <id>https://huran111.github.io/post/yi-tiao-sql-shi-ru-he-geng-xin-de</id>
        <link href="https://huran111.github.io/post/yi-tiao-sql-shi-ru-he-geng-xin-de">
        </link>
        <updated>2019-06-20T10:57:51.000Z</updated>
        <content type="html"><![CDATA[<pre><code>	+ 更新流程设计两个模块一个是redo log(重做日志),一个是binlog(归档日志)，Mysql里面有一个问题如果每次更新操作都需要写入磁盘，然后磁盘也要找到对应的那条记录，然后在更新，整个过程的IO成本都很高。 WAL技术也就是先写日志在写磁盘。
	+ 当一条记录需要更新的时候，InnoDB就会先把记录写到redo log里面，并更新内存，这个时候就算完成了，同时，Innodb引擎在适当的时候，将这个操作更新到磁盘里面。
	+ Innodb的redo log是固定大小的，可以配置一组为4个文件，每个文件1GB,从头开始写，写到末尾又回到开头循环写。
	+  有了redolog,Innodb就可以保证数据库发生异常重启，之前提交的记录都不会丢失，这个称为crash-safe
	+  redo log是Innodb层的，binlog是Mysql Server层的。
	+  两种日志的不同
	  + redolog是物理日志，记录的是在某个数据页上做了什么修改，binlog是逻辑日志，记录的是这个语句的原始逻辑。
	  + redolog是循环写，会覆盖，空间会用完，binlog是追加写，不会覆盖。
	  + update的语句时的执行流程
	  + ![](https://huran111.github.io/post-images/1561030115679.png)
	  + redolog被拆成了两个步骤，准备和提交
</code></pre>
<ul>
<li><strong>两阶段提交</strong>
<ul>
<li>当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据
<ul>
<li>找到最近的一次全量备份</li>
<li>从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。</li>
</ul>
</li>
<li>由于redolog和binlog是两个独立的逻辑，如果不用两阶段提交会有什么问题？</li>
<li>以 update T set c=c+1 where ID=2 为例</li>
<li><img src="https://huran111.github.io/post-images/1561084826449.png" alt=""></li>
<li><img src="https://huran111.github.io/post-images/1561084866299.png" alt="">
<ul>
<li><img src="https://huran111.github.io/post-images/1561029787476.png" alt=""></li>
<li>0：每秒将log buffer的内容写事务日志并且刷新到磁盘；</li>
<li>1：每个事务提交后，将log_buffer的内容写事务日志并刷新数据到磁盘；</li>
<li>2：每个事务提交，将log_buffer内容写事务日志，但不进行数据刷盘</li>
<li>mysql默认log_bin是关闭的</li>
<li><img src="https://huran111.github.io/post-images/1561030522520.png" alt=""></li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
</feed>